{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code was largely based on the OpenAI fine-tuning documentation and guide(https://platform.openai.com/docs/guides/fine-tuning).\n",
        "\n",
        "Dataset used: https://github.com/hate-alert/Countering_Hate_Speech_ICWSM2019/blob/master/Data/Counterspeech_Dataset.json"
      ],
      "metadata": {
        "id": "0jpnHcQ9m1HO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code blocks convert the json data into data that can be used for fine-tuning the GPT-3.5 model"
      ],
      "metadata": {
        "id": "L4gt0aXcm84f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdWyzewImykX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the dataset\n",
        "with open('Counterspeech_Dataset.json', 'r') as file:\n",
        "    dataset = json.load(file)\n",
        "\n",
        "# Create a new transformed dataset\n",
        "transformed_dataset = []\n",
        "\n",
        "def community_mapper(community):\n",
        "    \"\"\"Function to convert community names.\"\"\"\n",
        "    mapping = {\n",
        "        \"jews\": \"Jewish\",\n",
        "        \"black\": \"Black\",\n",
        "        \"lgbt\": \"LGBT\"\n",
        "    }\n",
        "    return mapping.get(community, community) # returns the community name if it's not in the dictionary\n",
        "\n",
        "for entry in dataset:\n",
        "    # Check if necessary keys are in the entry\n",
        "    if \"Community\" in entry and \"commentText\" in entry and \"CounterSpeech\" in entry:\n",
        "        community_name = community_mapper(entry[\"Community\"])\n",
        "        transformed_entry = {\n",
        "            \"Prompt\": f'A YouTube Video, which contains hateful content that targets the {community_name} community, has the following comment: {entry[\"commentText\"]}',\n",
        "            \"CounterSpeech\": entry[\"CounterSpeech\"] # enclosing the value in double quotes\n",
        "        }\n",
        "        transformed_dataset.append(transformed_entry)\n",
        "\n",
        "# Save the transformed dataset to a new JSON file\n",
        "with open('Transformed_Counterspeech_Dataset.json', 'w') as file:\n",
        "    json.dump(transformed_dataset, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Transformed_Counterspeech_Dataset.json\", \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Prepare the transformed data\n",
        "transformed_data = []\n",
        "\n",
        "system_message = \"You are an assistant that is meant to determine whether the comment mentioned in the user message is an example of counterspeech. Counterspeech is defined as a response or comment that counters hateful or harmful speech/ideas. Respond with true or false.\"\n",
        "\n",
        "for entry in data:\n",
        "    user_message_content = entry[\"Prompt\"]\n",
        "    assistant_message_content = \"true\" if entry[\"CounterSpeech\"] else \"false\"\n",
        "\n",
        "    message_group = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message_content},\n",
        "            {\"role\": \"assistant\", \"content\": assistant_message_content}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    transformed_data.append(message_group)\n",
        "\n",
        "# Save the transformed data to a new JSONL file\n",
        "with open(\"transformed_data.jsonl\", \"w\") as file:\n",
        "    for item in transformed_data:\n",
        "        json.dump(item, file)\n",
        "        file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "wLT_iZgxnFHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data from jsonl file\n",
        "with open('transformed_data.jsonl', 'r') as file:\n",
        "    data = [json.loads(line) for line in file]\n",
        "\n",
        "# Extract labels from data\n",
        "labels = [entry['messages'][2]['content'] for entry in data]\n",
        "\n",
        "# Split the data using stratified sampling to maintain the class balance\n",
        "#80% training data, 10% test data, 10% validation data\n",
        "train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=0.2, stratify=labels)\n",
        "valid_data, test_data, valid_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.5, stratify=temp_labels)\n",
        "\n",
        "# Save split data to separate jsonl files\n",
        "with open('train_data.jsonl', 'w') as file:\n",
        "    for item in train_data:\n",
        "        file.write(json.dumps(item) + '\\n')\n",
        "\n",
        "with open('valid_data.jsonl', 'w') as file:\n",
        "    for item in valid_data:\n",
        "        file.write(json.dumps(item) + '\\n')\n",
        "\n",
        "with open('test_data.jsonl', 'w') as file:\n",
        "    for item in test_data:\n",
        "        file.write(json.dumps(item) + '\\n')"
      ],
      "metadata": {
        "id": "_A96R5T0nG4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimate training cost"
      ],
      "metadata": {
        "id": "gUhF-3FCnYI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We start by importing the required packages\n",
        "\n",
        "import json\n",
        "import os\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Next, we specify the data path and open the JSONL file\n",
        "\n",
        "data_path = \"train_data.jsonl\"\n",
        "\n",
        "# Load dataset\n",
        "with open(data_path) as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# We can inspect the data quickly by checking the number of examples and the first item\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
        "\n",
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
        "\n",
        "# Token counting functions\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
        "\n",
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
        "\n",
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_EPOCHS = 1\n",
        "MAX_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "print(\"See pricing page to estimate total costs\")"
      ],
      "metadata": {
        "id": "l0bJb-YnnadY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "UTx5RhiLncl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = #<insert OpenAI API Key here>"
      ],
      "metadata": {
        "id": "U4hZajUfnfPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create fine-tuning file\n",
        "import openai\n",
        "import os\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "openai.File.create(\n",
        "  file=open(\"train_data.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "8WW3M5XYnhNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create fine-tuning job using the file id that is printed when you run the above code\n",
        "# 5 epochs were the most effective when we tried testing the fine-tuned model against the validation data\n",
        "# Run the code below\n",
        "#openai.FineTuningJob.create(training_file=<insert file-id>, model=\"gpt-3.5-turbo\", hyperparameters={\"n_epochs\": 5})\n",
        "\n",
        "#Store the fine-tuning job id, starts with \"ftjob-\""
      ],
      "metadata": {
        "id": "SW21A86pntVv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wait some time and run this line\n",
        "#openai.FineTuningJob.retrieve(<insert fine-tuning job id>)\n",
        "#Wait some time in-between each time you run it, eventually you should see that the \"status\" says succeeded\n",
        "#There should be a fine-tuned model, which you should store"
      ],
      "metadata": {
        "id": "xUISGXkVnxBs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code provides the results and metrics"
      ],
      "metadata": {
        "id": "ejqlvT0To3m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the test data\n",
        "with open(\"test_data.jsonl\", \"r\") as f:\n",
        "    valid_data = [json.loads(line) for line in f]\n",
        "\n",
        "# Initialize the lists for true labels and predictions\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Get predictions for each example in validation data\n",
        "for example in valid_data:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"ft:gpt-3.5-turbo-0613:personal::7tptzfbo\", #replace this with your model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant that is meant to determine whether the comment mentioned in the user message is an example of counterspeech. Counterspeech is defined as a response or comment that counters hateful or harmful speech/ideas. Respond with true or false.\"},\n",
        "            {\"role\": \"user\", \"content\": example[\"messages\"][1][\"content\"]}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    predicted = completion.choices[0].message[\"content\"].lower()\n",
        "    true = example[\"messages\"][2][\"content\"].lower()\n",
        "\n",
        "    predicted_labels.append(predicted)\n",
        "    true_labels.append(true)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, pos_label=\"true\")\n",
        "recall = recall_score(true_labels, predicted_labels, pos_label=\"true\")\n",
        "f1 = f1_score(true_labels, predicted_labels, pos_label=\"true\")\n",
        "\n",
        "# Find which examples were incorrect\n",
        "incorrect_examples = [example for i, example in enumerate(valid_data) if true_labels[i] != predicted_labels[i]]\n",
        "correct_examples = [example for i, example in enumerate(valid_data) if true_labels[i] == predicted_labels[i]]\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(\"\\nIncorrect Examples:\")\n",
        "for example in incorrect_examples:\n",
        "    print(example)\n",
        "print(\"\\nCorrect Examples:\")\n",
        "for example in correct_examples:\n",
        "    print(example)\n"
      ],
      "metadata": {
        "id": "sqSPc5eGoUIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}