{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYei1kZmpiW8"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score\n",
        "\n",
        "# Set API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = #<insert API Key>\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Read the .jsonl file\n",
        "# Use test_data.jsonl from GPT-3.5 fine-tuning code\n",
        "data = []\n",
        "with open('test_data.jsonl', 'r') as file:\n",
        "    for line in file:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "# Lists to store actual and predicted values\n",
        "actual = []\n",
        "predicted = []\n",
        "\n",
        "# Go through each example and predict\n",
        "for example in data:\n",
        "    # Extract messages without the assistant's message\n",
        "    messages = example[\"messages\"][:-1]\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0\n",
        "        )\n",
        "        predicted_response = response[\"choices\"][0][\"message\"][\"content\"].lower()\n",
        "\n",
        "        # Check the response and treat any non-true responses as 'false'\n",
        "        if predicted_response not in ['true', 'false']:\n",
        "            predicted_response = 'false'\n",
        "\n",
        "        predicted.append(predicted_response)\n",
        "        actual_response = example[\"messages\"][-1][\"content\"].lower()\n",
        "        actual.append(actual_response)\n",
        "    except Exception as e:\n",
        "        print(\"Error for example:\", messages)\n",
        "        print(e)\n",
        "\n",
        "    time.sleep(1)  # Wait for 1 second before the next request\n",
        "\n",
        "# Metrics\n",
        "print(\"Accuracy:\", accuracy_score(actual, predicted))\n",
        "print(\"F1-score:\", f1_score(actual, predicted, pos_label=\"true\"))\n",
        "print(\"Precision:\", precision_score(actual, predicted, pos_label=\"true\"))\n",
        "print(\"Recall:\", recall_score(actual, predicted, pos_label=\"true\"))\n",
        "print(classification_report(actual, predicted, target_names=[\"false\", \"true\"]))\n",
        "\n",
        "# Displaying examples\n",
        "correct = []\n",
        "incorrect = []\n",
        "\n",
        "for a, p, ex in zip(actual, predicted, data):\n",
        "    if a == p:\n",
        "        correct.append(ex)\n",
        "    else:\n",
        "        incorrect.append(ex)\n",
        "\n",
        "print(\"\\nExamples GPT-3.5 got right:\")\n",
        "for c in correct:\n",
        "    print(c)\n",
        "\n",
        "print(\"\\nExamples GPT-3.5 got wrong:\")\n",
        "for ic in incorrect:\n",
        "    print(ic)\n"
      ],
      "metadata": {
        "id": "4tEkbgodpyqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}